{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bf3d4f2d-dd91-4cbd-859c-fb276f9047d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device= cpu\n",
      "loading data...\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import traceback\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split as ts\n",
    "from sklearn.metrics import roc_curve,auc,roc_auc_score,precision_recall_curve\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from plotnine import *\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device=\",device)\n",
    "\n",
    "black = '#222222'\n",
    "gray = '#666666'\n",
    "red = '#FF3333'\n",
    "green = '#66CC00'\n",
    "blue = '#3333FF'\n",
    "purple = '#9933FF'\n",
    "orange = '#FF8000'\n",
    "yellow = '#FFFF33'\n",
    "\n",
    "\n",
    "\n",
    "class Config:\n",
    "\n",
    "    train_dir=\"m5C/feature/train/\"\n",
    "    test_dir=\"ELIGOS_C/feature/test/\"\n",
    "    #train_dir = \"data/motif/CTCAC/train/\"\n",
    "    #test_dir = \"data/motif/CTCAC/test/\"\n",
    "    batch_size = 500\n",
    "    learning_rate=0.00001\n",
    "    \n",
    "    \n",
    "kmer_encode_dic={'A': 0, \"C\": 1, \"G\": 2, \"T\": 3}   \n",
    "\n",
    "class BahdanauAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Bahdanau Attention mechanism module.\n",
    "\n",
    "    Args:\n",
    "        in_features (int): Number of input features.\n",
    "        hidden_units (int): Number of hidden units.\n",
    "        num_task (int): Number of tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self,in_features, hidden_units,num_task):\n",
    "        super(BahdanauAttention,self).__init__()\n",
    "        self.W1 = nn.Linear(in_features=in_features,out_features=hidden_units)\n",
    "        self.W2 = nn.Linear(in_features=in_features,out_features=hidden_units)\n",
    "        self.V = nn.Linear(in_features=hidden_units, out_features=num_task)\n",
    "\n",
    "    def forward(self, hidden_states, values):\n",
    "        hidden_with_time_axis = torch.unsqueeze(hidden_states,dim=1)\n",
    "\n",
    "        score  = self.V(nn.Tanh()(self.W1(values)+self.W2(hidden_with_time_axis)))\n",
    "        attention_weights = nn.Softmax(dim=1)(score)\n",
    "        values = torch.transpose(values,1,2)   # transpose to make it suitable for matrix multiplication\n",
    "        #print(attention_weights.shape,values.shape)\n",
    "        context_vector = torch.matmul(values,attention_weights)\n",
    "        context_vector = torch.transpose(context_vector,1,2)\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "class TandemMod(nn.Module):\n",
    "    def __init__(self,num_classes=2,vocab_zie=5, embedding_size=4,seq_len=5):\n",
    "        super(TandemMod,self).__init__()\n",
    "\n",
    "        self.seq_len=seq_len\n",
    "        self.embed = nn.Embedding(vocab_zie, embedding_size)\n",
    "\n",
    "        self.cnn_1d = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1,out_channels=64,kernel_size=7,stride=2,padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv1d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2,padding=1),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv1d(in_channels=128,out_channels=128,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2,padding=1),\n",
    "\n",
    "        )\n",
    "        self.lstm=nn.LSTM(input_size=128,hidden_size=128,batch_first=True,bidirectional=True)\n",
    "        self.attention=BahdanauAttention(in_features=256,hidden_units=10,num_task=1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=1536,out_features=1536),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1536, out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512,out_features=2)\n",
    "        )\n",
    "\n",
    "        self.lstm_seq=nn.LSTM(input_size=4+5,hidden_size=128,batch_first=True,bidirectional=True)   #embedding_size+feature_num\n",
    "\n",
    "\n",
    "    def seq_to_digit(self,seq):\n",
    "        return torch.Tensor([{'A': 0, \"C\": 1, \"G\": 2, \"T\": 3}[i] for i in list(seq)]).long()\n",
    "\n",
    "\n",
    "    def forward(self,x,kmer,mean,std,intense,dwell,base_quality):\n",
    "        kmer_embedded=self.embed(kmer)\n",
    "        mean = torch.reshape(mean, (-1, self.seq_len, 1)).float()\n",
    "        std = torch.reshape(std, (-1, self.seq_len, 1)).float()\n",
    "        intense = torch.reshape(intense, (-1, self.seq_len, 1)).float()\n",
    "        dwell = torch.reshape(dwell, (-1, self.seq_len, 1)).float()\n",
    "        base_quality = torch.reshape(base_quality, (-1, self.seq_len, 1)).float()\n",
    "        \n",
    "        out_seq=torch.cat((kmer_embedded,mean,std,intense,dwell,base_quality),2)\n",
    "\n",
    "\n",
    "        out_seq,(h_n_seq,c_n_seq)=self.lstm_seq(out_seq)\n",
    "\n",
    "        x = self.cnn_1d(x)\n",
    "\n",
    "        batch_size, features, seq_len = x.size()\n",
    "        x = x.view(batch_size, seq_len, features)  # parepare input for LSTM\n",
    "\n",
    "        output, (h_n, c_n) = self.lstm(x)\n",
    "\n",
    "        h_n = h_n.view(batch_size, output.size()[-1])  # pareprae input for Attention\n",
    "        context_vector, attention_weights = self.attention(h_n, output)  # Attention (batch_size, num_task, unit)\n",
    "\n",
    "\n",
    "        out=torch.cat((out_seq[:,0,:],out_seq[:,1,:],out_seq[:,2,:],out_seq[:,3,:],out_seq[:,4,:],context_vector[:,0,:]),1)\n",
    "        #out=context_vector[:,0,:]\n",
    "        out.view(out.size()[0],1,out.size()[1])\n",
    "        x=self.fc(out)\n",
    "        #x.view(x.size()[0], 1, x.size()[1])\n",
    "        return x\n",
    "\n",
    "\n",
    "class NN(TandemMod):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the NN class.\n",
    "        Inherits from the TandemMod class.\n",
    "        \"\"\"\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset class.\n",
    "\n",
    "    Args:\n",
    "        x (list or numpy array): Input data.\n",
    "        y (list or numpy array): Target data.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,x,y):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index],self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "\n",
    "def make_weights_for_balanced_classes(images, nclasses):\n",
    "    \"\"\"\n",
    "    Computes weights for balancing classes in a dataset.\n",
    "\n",
    "    Args:\n",
    "        images (list): List of images.\n",
    "        nclasses (int): Number of classes.\n",
    "\n",
    "    Returns:\n",
    "        list: List of weights.\n",
    "\n",
    "    \"\"\"\n",
    "    count = [0] * nclasses\n",
    "    for item in images:\n",
    "        count[item[1]] += 1\n",
    "    weight_per_class = [0.] * nclasses\n",
    "    N = float(sum(count))\n",
    "    for i in range(nclasses):\n",
    "        weight_per_class[i] = N/float(count[i])\n",
    "    weight = [0] * len(images)\n",
    "    for idx, val in enumerate(images):\n",
    "        weight[idx] = weight_per_class[val[1]]\n",
    "    return weight\n",
    "\n",
    "\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "class CustomWeightedRandomSampler(WeightedRandomSampler):\n",
    "    \"\"\"\n",
    "    Custom implementation of WeightedRandomSampler.\n",
    "    WeightedRandomSampler except allows for more than 2^24 samples to be sampled\n",
    "    Args:\n",
    "        *args: Variable length argument list.\n",
    "        **kwargs: Arbitrary keyword arguments.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def __iter__(self):\n",
    "        rand_tensor = np.random.choice(range(0, len(self.weights)),\n",
    "                                       size=self.num_samples,\n",
    "                                       p=self.weights.numpy() / torch.sum(self.weights).numpy(),\n",
    "                                       replace=self.replacement)\n",
    "        rand_tensor = torch.from_numpy(rand_tensor)\n",
    "        return iter(rand_tensor.tolist())\n",
    "\n",
    "print(\"loading data...\")\n",
    "\n",
    "model = TandemMod(num_classes=2,vocab_zie=5, embedding_size=4,seq_len=5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()#.to(device)\n",
    "#predict_result=open(\"rice/results/WT_precit_results.tsv\",\"w\")\n",
    "\n",
    "def predict(model,dataset,cut_off_threshold):\n",
    "    \"\"\"\n",
    "    Predicts the output of the model on the given dataset.\n",
    "\n",
    "    Parameters:\n",
    "        model (nn.Module): The trained model to use for prediction.\n",
    "        dataset (torch.utils.data.Dataset): The dataset to predict on.\n",
    "\n",
    "    Returns:\n",
    "        fpr (array): False positive rates.\n",
    "        tpr (array): True positive rates.\n",
    "        precision (array): Precision values.\n",
    "        recall (array): Recall values.\n",
    "        roc_auc (float): Area under the ROC curve.\n",
    "        pr_auc (float): Area under the precision-recall curve.\n",
    "    \"\"\"\n",
    "\n",
    "    dataloader=torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                           batch_size=4000, \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=36,\n",
    "                                           pin_memory=True)\n",
    "\n",
    "    try:\n",
    "\n",
    "        test_acc = 0.\n",
    "        y_test = []\n",
    "        y_pred = []\n",
    "        label_dict={0:\"m5C\",1:\"C\"}\n",
    "        \n",
    "        probabilities_all=[]\n",
    "        labels=[]\n",
    "        \n",
    "        for i,(batch_x, batch_y) in enumerate(dataloader):\n",
    "\n",
    "            signal, kmer, mean, std, intense, dwell,base_quality = batch_x\n",
    "            signal= Variable(signal.to(device)).to(torch.float32)\n",
    "\n",
    "            kmer = Variable(kmer.to(device)).to(torch.long)\n",
    "            mean = Variable(mean.to(device)).to(torch.float32)\n",
    "            std = Variable(std.to(device)).to(torch.float32)\n",
    "            intense = Variable(intense.to(device)).to(torch.float32)\n",
    "            dwell = Variable(dwell.to(device)).to(torch.float32)\n",
    "            base_quality = Variable(base_quality.to(device)).to(torch.float32)\n",
    "            batch_size, features = signal.size()\n",
    "            signal = signal.view(batch_size, 1, features)\n",
    "\n",
    "            out = model(signal, kmer, mean, std, intense, dwell,base_quality )\n",
    "            batch_size, out_channels = out.size()\n",
    "\n",
    "            out = out.view(batch_size, out_channels)\n",
    "            pred = torch.max(out, 1)[1].numpy()\n",
    "\n",
    "            out=torch.softmax(out,dim=1)\n",
    "            probabilities=out.detach().numpy()[:,1]\n",
    "            batch_y=batch_y.detach().numpy()\n",
    "            #print(probabilities)\n",
    "            \n",
    "            \n",
    "            selected_batch_y=[]\n",
    "            selected_probabilities=[]\n",
    "            for j in range(len(batch_y)):\n",
    "                if probabilities[j]<cut_off_threshold[0] or probabilities[j]>cut_off_threshold[1]:\n",
    "                    selected_batch_y.append(batch_y[j])\n",
    "                    selected_probabilities.append(probabilities[j])\n",
    "            \n",
    "            print(\"Probability cutoff:\",cut_off_threshold[0],cut_off_threshold[1],\"\\tPreserved sites:\",len(selected_batch_y))\n",
    "            fpr,tpr,thersholds=roc_curve(selected_batch_y,selected_probabilities)\n",
    "            precision,recall,thersholds=precision_recall_curve(selected_batch_y,selected_probabilities)\n",
    "            \n",
    "            roc_auc=auc(fpr,tpr)\n",
    "            pr_auc=auc(recall,precision)\n",
    "           \n",
    "            probabilities_all.extend(list(probabilities))\n",
    "            labels.extend(list(batch_y))\n",
    "            return fpr,tpr,precision,recall,roc_auc,pr_auc,len(selected_batch_y)/len(batch_y),probabilities,batch_y\n",
    "        return probabilities_all,labels\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        traceback.print_exc()\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Extract feature from signal.')\n",
    "    parser.add_argument('-feature', default='BaseCalled_template',help='Basecall subgroup Nanoraw resquiggle into. Default is BaseCalled_template')\n",
    "    args = parser.parse_args()\n",
    "  \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a798e1-7152-40b5-b08b-c1838bed5743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfdcbce7-8586-47b1-8e1c-629354351d97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kmer_encode_dic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_106923/1355143971.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#signal=(signal-np.mean(signal))/np.std(signal)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mkmer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mkmer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkmer_encode_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkmer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_106923/1355143971.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#signal=(signal-np.mean(signal))/np.std(signal)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mkmer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mkmer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkmer_encode_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkmer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kmer_encode_dic' is not defined"
     ]
    }
   ],
   "source": [
    "#test on curcake ac4C\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "x_test_median_mad,y_test_median_mad,site_list=[],[],[]\n",
    "#f=open(\"/home/wuyou/Projects/paper/yeast_C.feature.tsv\")\n",
    "f=open(\"/home/wuyou/Projects/ac4c/data/curlcake_ac4C.feature.tsv\")\n",
    "for i,line in enumerate(f):\n",
    "    if i>3e3:\n",
    "        break\n",
    "    line=line.rstrip()\n",
    "    items=line.split(\"\\t\")\n",
    "    read_id=line.split(\"\\t\")[0]\n",
    "    site=int(line.split(\"\\t\")[2])\n",
    "\n",
    "        #pass\n",
    "    #if not read_id_dict.get(read_id,0):\n",
    "    #    continue\n",
    "\n",
    "    signals=\"|\".join(items[9:14]).split(\"|\")\n",
    "    signal=np.array([float(signal) for signal in signals])\n",
    "    #signal=(signal-np.mean(signal))/np.std(signal)\n",
    "    kmer = items[3]\n",
    "    kmer=np.array([kmer_encode_dic[base] for base in kmer])\n",
    "    mean = np.array([float(item) for item in items[4].split(\"|\")])\n",
    "    std = np.array([float(item) for item in items[5].split(\"|\")])\n",
    "    intense = np.array([float(item) for item in items[6].split(\"|\")])\n",
    "    dwell = np.array([float(item) for item in items[7].split(\"|\")])/200\n",
    "    base_quality = np.array([float(item) for item in items[8].split(\"|\")])/40\n",
    "    x=[signal, kmer, mean, std, intense, dwell,base_quality]\n",
    "    x_test_median_mad.append(x)\n",
    "    y_test_median_mad.append(0)\n",
    "    site_list.append(site)\n",
    "f.close()\n",
    "\n",
    "dataset=MyDataset(x_test_median_mad,y_test_median_mad)\n",
    "\n",
    "\n",
    "#model= torch.load('/home/wuyou/Projects/paper/model/m6A_Os_AD_median_mad_length_1000.pkl')\n",
    "model = torch.load(\"/data/wuyou/ac4c/model/ac4C_C.pkl\",map_location=torch.device(\"cpu\"))\n",
    "\n",
    "#fpr,tpr,precision,recall,roc_auc_MMAD,pr_auc_MMAD,preserved_ratio,probabilities,labels=predict(model,dataset,[0.5,0.5])\n",
    "probabilities,labels=predict(model,dataset,[0.5,0.5])\n",
    "print(44,labels)\n",
    "data=pd.DataFrame(dict(Probabilities=probabilities,label=labels)) \n",
    "\n",
    "data_C=data[data[\"label\"]==0]\n",
    "print(data)\n",
    "#data.to_csv(\"data/density_of_reads_probablilities_m5C_on_ELIGOS.csv\")\n",
    "p1 = (ggplot()\n",
    "        #+geom_bar(data,aes(x=\"Probabilities\",y = \"Proportion\"),stat=\"identity\",width=0.6)\n",
    "        +geom_density(data_C,aes(x=\"Probabilities\",fill=\"black\",color=\"black\"),alpha=0.1,show_legend=False)\n",
    "        +theme(panel_background=element_rect(fill=gray, alpha=0),\n",
    "            panel_grid_major=element_line(size=0.3, alpha=0,color=black),\n",
    "            panel_grid_minor=element_line(size=0.3, alpha=0,color=black),\n",
    "            panel_border=element_rect(color=black, size=1),\n",
    "            axis_text=element_text(size=6,family=\"Arial\",color=\"black\"),\n",
    "            axis_title_x=element_text(size=6,family=\"Arial\",color=\"black\"),\n",
    "            axis_title_y=element_text(size=6,family=\"Arial\",color=\"black\"),\n",
    "            plot_title=element_text(margin={'b': 1, 'r': 0, 'units': 'pt'},size=6,family=\"Arial\",color=\"black\",hjust=0.5),\n",
    "            #axis_text_x=element_text(rotation=45, hjust=0.5),\n",
    "            figure_size=[1.52,1.53],\n",
    "            #legend_title = element_text(size=6), #change legend title font size\n",
    "            #legend_text = element_text(size=6),\n",
    "            #legend_background=element_rect(size=0.5,alpha=0),\n",
    "            legend_position=(0.60,0.4),\n",
    "            #legend_key_size=4   #change legend text font size\n",
    "              ) \n",
    "       +xlim([0,1])\n",
    "        +labs(x = \"Predicted ac4C probabilities\", y =\"Density\")\n",
    "        #guides(color = guide_legend(title = \"Probability cutoff\"))\n",
    "      +ggtitle(\"Curlcake ac4C dataset\")\n",
    "\n",
    ")\n",
    "print(p1)\n",
    "p1.save(\"figure/validation_IVET_ac4C_model_on_curlcake_ac4C_dataset.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43a848d-f0f7-40df-ac60-86e6c17e8956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dda65c1d-4c79-4c99-8346-f08b306789e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability cutoff: 0.5 0.5 \tPreserved sites: 4000\n",
      "Probability cutoff: 0.5 0.5 \tPreserved sites: 2002\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 152x153 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#test on curcake ac4C\n",
    "#\n",
    "\n",
    "black = '#222222'\n",
    "gray = '#666666'\n",
    "red = '#FF3333'\n",
    "green = '#66CC00'\n",
    "blue = '#3333FF'\n",
    "purple = '#9933FF'\n",
    "orange = '#FF8000'\n",
    "yellow = '#FFFF33'\n",
    "c1=\"#F8766D\"\n",
    "c2=\"#00BA38\" \n",
    "c3=\"#619CFF\"\n",
    "\n",
    "x_test_median_mad,y_test_median_mad,site_list=[],[],[]\n",
    "#f=open(\"/home/wuyou/Projects/paper/yeast_C.feature.tsv\")\n",
    "f=open(\"/home/wuyou/Projects/paper/m5C/feature/median_mad/unmod.test\")\n",
    "for i,line in enumerate(f):\n",
    "    if i>3e3:\n",
    "        break\n",
    "    line=line.rstrip()\n",
    "    items=line.split(\"\\t\")\n",
    "    read_id=line.split(\"\\t\")[0]\n",
    "    site=int(line.split(\"\\t\")[2])\n",
    "\n",
    "        #pass\n",
    "    #if not read_id_dict.get(read_id,0):\n",
    "    #    continue\n",
    "\n",
    "    signals=\"|\".join(items[9:14]).split(\"|\")\n",
    "    signal=np.array([float(signal) for signal in signals])\n",
    "    #signal=(signal-np.mean(signal))/np.std(signal)\n",
    "    kmer = items[3]\n",
    "    kmer=np.array([kmer_encode_dic[base] for base in kmer])\n",
    "    mean = np.array([float(item) for item in items[4].split(\"|\")])\n",
    "    std = np.array([float(item) for item in items[5].split(\"|\")])\n",
    "    intense = np.array([float(item) for item in items[6].split(\"|\")])\n",
    "    dwell = np.array([float(item) for item in items[7].split(\"|\")])/200\n",
    "    base_quality = np.array([float(item) for item in items[8].split(\"|\")])/40\n",
    "    x=[signal, kmer, mean, std, intense, dwell,base_quality]\n",
    "    x_test_median_mad.append(x)\n",
    "    y_test_median_mad.append(0)\n",
    "    site_list.append(site)\n",
    "f.close()\n",
    "\n",
    "\n",
    "f=open(\"/home/wuyou/Projects/ac4c/data/curlcake_ac4C.feature.tsv\")\n",
    "for i,line in enumerate(f):\n",
    "    if i>3e3:\n",
    "        break\n",
    "    line=line.rstrip()\n",
    "    items=line.split(\"\\t\")\n",
    "    read_id=line.split(\"\\t\")[0]\n",
    "    site=int(line.split(\"\\t\")[2])\n",
    "\n",
    "        #pass\n",
    "    #if not read_id_dict.get(read_id,0):\n",
    "    #    continue\n",
    "\n",
    "    signals=\"|\".join(items[9:14]).split(\"|\")\n",
    "    signal=np.array([float(signal) for signal in signals])\n",
    "    #signal=(signal-np.mean(signal))/np.std(signal)\n",
    "    kmer = items[3]\n",
    "    kmer=np.array([kmer_encode_dic[base] for base in kmer])\n",
    "    mean = np.array([float(item) for item in items[4].split(\"|\")])\n",
    "    std = np.array([float(item) for item in items[5].split(\"|\")])\n",
    "    intense = np.array([float(item) for item in items[6].split(\"|\")])\n",
    "    dwell = np.array([float(item) for item in items[7].split(\"|\")])/200\n",
    "    base_quality = np.array([float(item) for item in items[8].split(\"|\")])/40\n",
    "    x=[signal, kmer, mean, std, intense, dwell,base_quality]\n",
    "    x_test_median_mad.append(x)\n",
    "    y_test_median_mad.append(1)\n",
    "    site_list.append(site)\n",
    "f.close()\n",
    "\n",
    "\n",
    "dataset=MyDataset(x_test_median_mad,y_test_median_mad)\n",
    "\n",
    "\n",
    "#model= torch.load('/home/wuyou/Projects/paper/model/m6A_Os_AD_median_mad_length_1000.pkl')\n",
    "model = torch.load(\"/data/wuyou/ac4c/model/ac4C_C.pkl\",map_location=torch.device(\"cpu\"))\n",
    "\n",
    "#fpr,tpr,precision,recall,roc_auc_MMAD,pr_auc_MMAD,preserved_ratio,probabilities,labels=predict(model,dataset,[0.5,0.5])\n",
    "probabilities,labels=predict(model,dataset,[0.5,0.5])\n",
    "\n",
    "data=pd.DataFrame(dict(Probabilities=probabilities,label=labels)) \n",
    "\n",
    "data[\"label\"]=data[\"label\"].astype(str)\n",
    "#data_C=data[data[\"label\"]==0]\n",
    "#print(data)\n",
    "#data.to_csv(\"data/density_of_reads_probablilities_m5C_on_ELIGOS.csv\")\n",
    "p1 = (ggplot()\n",
    "        #+geom_bar(data,aes(x=\"Probabilities\",y = \"Proportion\"),stat=\"identity\",width=0.6)\n",
    "        +geom_density(data,aes(x=\"Probabilities\",fill=\"label\",color=\"label\",group=\"label\"),alpha=0.2,show_legend=True)\n",
    "        +theme(panel_background=element_rect(fill=gray, alpha=0),\n",
    "            panel_grid_major=element_line(size=0.3, alpha=0,color=black),\n",
    "            panel_grid_minor=element_line(size=0.3, alpha=0,color=black),\n",
    "            panel_border=element_rect(color=black, size=1),\n",
    "            axis_text=element_text(size=6,family=\"Arial\",color=\"black\"),\n",
    "            axis_title_x=element_text(size=6,family=\"Arial\",color=\"black\"),\n",
    "            axis_title_y=element_text(size=6,family=\"Arial\",color=\"black\"),\n",
    "            plot_title=element_text(margin={'b': 1, 'r': 0, 'units': 'pt'},size=6,family=\"Arial\",color=\"black\",hjust=0.5),\n",
    "            #axis_text_x=element_text(rotation=45, hjust=0.5),\n",
    "            figure_size=[1.52,1.53],\n",
    "            legend_title = element_text(size=6), #change legend title font size\n",
    "            legend_text = element_text(size=6),\n",
    "            legend_background=element_rect(size=0.5,alpha=0),\n",
    "            legend_position=(0.25,0.8),\n",
    "            legend_key_size=4   #change legend text font size\n",
    "              ) \n",
    "       +xlim([0,1])\n",
    "       +labs(x = \"Prediction probabilities\", y =\"Density\")\n",
    "       +guides(color = guide_legend(title = \"\",label=[\"0\",\"b\"]),\n",
    "              fill = guide_legend(title = \"\",label=[\"0\",\"b\"]),)\n",
    "       +ggtitle(\"Curlcake C dataset\")\n",
    "       +scale_fill_manual([c1,c2])\n",
    "       +scale_color_manual([c1,c2])\n",
    ")\n",
    "print(p1)\n",
    "p1.save(\"figure/validation_IVET_ac4C_model_on_curlcake_C_dataset.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b181cf81-88c1-47ad-aec8-fad022f6582d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
